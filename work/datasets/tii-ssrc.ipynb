{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65477e59-d200-4fc1-a9ad-b399814d11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from common import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d72e79-71a1-4e69-918f-dfd75defdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = common.base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c7e10f-2e2c-4edd-8016-cf7f16111a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tii_ssrc_df():\n",
    "    config = {\n",
    "        'TARGET_COLUMN': 'Traffic Type',\n",
    "        # List of numerical columns (these are to be standardized)\n",
    "        'NUMERICAL_COLUMNS': [],\n",
    "        # List of categorical columns (these are to be one hot encoded)\n",
    "        'CATEGORICAL_COLUMNS': [],\n",
    "        # List of ordinal columns (these are to be label encoded)\n",
    "        'ORDINAL_COLUMNS': [],\n",
    "    }\n",
    "    target_column = config['TARGET_COLUMN']\n",
    "    all_df = pd.read_csv(f'{base_path}/datasources/tii-ssrc/sampled_data.csv')\n",
    "    \n",
    "    # Headers of column\n",
    "    main_labels = all_df.columns\n",
    "    \n",
    "    print('Normal class: ', all_df[target_column].mode())\n",
    "    return (all_df, main_labels, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4d161f-1a56-4e2f-ba87-f9e14237a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_tii_ssrc_df():\n",
    "    all_df, main_labels, config = get_tii_ssrc_df()\n",
    "    # print('main_labels', main_labels)\n",
    "    target_column = config['TARGET_COLUMN']\n",
    "\n",
    "    # Preprocess\n",
    "    DROP_COLUMNS = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Timestamp']\n",
    "    all_df = all_df.drop(columns=DROP_COLUMNS)\n",
    "    \n",
    "    # Filter out duplicates within the same target\n",
    "    all_df = all_df.round(3)\n",
    "    all_df = all_df.drop_duplicates()\n",
    "    all_df = all_df.drop(columns=['Label', 'Traffic Subtype'])\n",
    "\n",
    "    numerical_cols = all_df.select_dtypes(include=[np.number]).columns.to_list()\n",
    "    numerical_cols.remove('Protocol')\n",
    "    print('numerical_cols', numerical_cols)\n",
    "    categorical_cols = all_df.select_dtypes(include=[object]).columns.to_list()\n",
    "    categorical_cols.append('Protocol')\n",
    "    print('categorical_cols', categorical_cols)\n",
    "    \n",
    "    # Pipelines for Numerical and Categorical Data Transformations\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # Column Transformer combining both pipelines\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Apply preprocessor to train and test data\n",
    "    preprocessor.fit(all_df)\n",
    "\n",
    "    # Label Encoder\n",
    "    le, all_df = common.label_encode(all_df, [target_column])\n",
    "    \n",
    "    config['TARGET_DICT'] = {index: label for index, label in enumerate(le.classes_)}\n",
    "    config['INV_TARGET_DICT'] = {v: k for k, v in config['TARGET_DICT'].items()}\n",
    "    print('TARGET_DICT', config['TARGET_DICT'])\n",
    "    le, all_df = common.label_encode(all_df, config['ORDINAL_COLUMNS'])\n",
    "    \n",
    "    config['NORMAL_TARGET'] = config['INV_TARGET_DICT']['Bruteforce']\n",
    "    print('NORMAL_TARGET', config['NORMAL_TARGET'])\n",
    "\n",
    "    # One Hot Encoder\n",
    "    ohe, all_df = common.one_hot_encode(all_df, config['CATEGORICAL_COLUMNS'])\n",
    "    \n",
    "    main_labels = list(all_df.columns)\n",
    "    print('main_labels', main_labels)\n",
    "    \n",
    "    return (all_df, main_labels, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d2126-6c4f-40c4-82e3-706df6f35fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
