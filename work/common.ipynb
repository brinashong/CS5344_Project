{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b16da7f-91fb-495d-bade-a254058e90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, predictions, heading='-----Evaluation-----'):\n",
    "    print(heading)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    categories = np.unique(y_test)\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in categories], columns = [i for i in categories])\n",
    "    sns.heatmap(df_cm,annot=True,cmap='Reds')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "    cr = classification_report(y_test, predictions, output_dict=True)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(cr)\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    return (cm, cr, acc)\n",
    "\n",
    "def remove_files_from_directory(directory):\n",
    "    # Get all files in the directory\n",
    "    files = glob.glob(os.path.join(directory, \"*\"))\n",
    "    \n",
    "    # Loop through the files and remove each one\n",
    "    for file in files:\n",
    "        if os.path.isfile(file):\n",
    "            os.remove(file)\n",
    "    \n",
    "    print(f\"All files in {directory} have been removed.\")\n",
    "\n",
    "def get_anomaly_X_y_from_csv(csv_file, main_labels, target_column, normal_target, output_folder):\n",
    "    df=pd.read_csv(os.path.join(output_folder, csv_file),usecols=main_labels)\n",
    "    df=df.fillna(0)\n",
    "    anomaly_or_not=[]\n",
    "    for i in df[target_column]: #it changes the normal label to \"1\" and the anomaly tag to \"0\" for use in the machine learning algorithm\n",
    "        if i == normal_target:\n",
    "            anomaly_or_not.append(1)\n",
    "        else:\n",
    "            anomaly_or_not.append(0)           \n",
    "    df[target_column]=anomaly_or_not\n",
    "\n",
    "    # y = df[target_column].values\n",
    "    # del df[target_column]\n",
    "    # X = df.values\n",
    "    y_df = df[target_column]\n",
    "    X_df = df.drop(columns=[target_column])\n",
    "    \n",
    "    # X = np.float32(X)\n",
    "    # X[np.isnan(X)] = 0\n",
    "    # X[np.isinf(X)] = 0\n",
    "    # print('X', type(X), X)\n",
    "    # print('y', type(y), y)\n",
    "    return (X_df, y_df, df)\n",
    "\n",
    "def one_hot_encode(df, categorical_columns):\n",
    "    # Initialize the OneHotEncoder\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    \n",
    "    # Make a copy of the DataFrame to keep track of column order\n",
    "    X_encoded = df.copy()\n",
    "    \n",
    "    # Loop over categorical columns to encode them one by one and retain column order\n",
    "    for col in categorical_columns:\n",
    "        # Get the position (index) of the categorical column in the original DataFrame\n",
    "        col_position = X_encoded.columns.get_loc(col)\n",
    "        \n",
    "        # Reshape the column to a 2D array and apply one-hot encoding\n",
    "        encoded_array = ohe.fit_transform(X_encoded[[col]])\n",
    "        \n",
    "        # Create a DataFrame for the one-hot encoded columns\n",
    "        encoded_columns = ohe.get_feature_names_out([col])\n",
    "        encoded_df = pd.DataFrame(encoded_array, columns=encoded_columns, index=X_encoded.index)\n",
    "        \n",
    "        # Drop the original categorical column from the DataFrame\n",
    "        X_encoded = X_encoded.drop(columns=[col])\n",
    "        \n",
    "        # Insert the one-hot encoded columns back into the DataFrame at the original column's position\n",
    "        for i, new_col in enumerate(encoded_columns):\n",
    "            X_encoded.insert(col_position + i, new_col, encoded_df.iloc[:, i])\n",
    "    \n",
    "    # X_encoded now contains the one-hot encoded features in the correct positions\n",
    "    print(list(X_encoded.columns))\n",
    "    return (ohe, X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b2db07-4c69-4ac5-8465-061761bf7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing_values(all_df):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    sns.heatmap(all_df.isnull(),cbar=False,cmap='Wistia',yticklabels=False)\n",
    "    plt.title('Missing value in the dataset');\n",
    "\n",
    "def show_target_values(all_df, target_column):\n",
    "    target_counts = all_df[target_column].value_counts()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,7))\n",
    "    target_counts_barplot = sns.barplot(x = target_counts.index,y = target_counts.values, ax = ax[0], hue=target_counts.index, palette='Set2', legend=False)\n",
    "    target_counts_barplot.set_ylabel('Number of classes in the dataset')\n",
    "    \n",
    "    target_counts.plot.pie(autopct=\"%1.1f%%\", ax=ax[1])\n",
    "\n",
    "def show_feature_correlation(all_df):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.heatmap(all_df.corr(), cmap='hsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ec0dd-845a-40cd-ac58-e6cb4be0e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_log(conf_matrix, class_report, acc_score):\n",
    "    wandb.log({\n",
    "        \"Accuracy Score\": acc_score\n",
    "    })\n",
    "        \n",
    "    # Create a table for classification metrics\n",
    "    class_report_table = wandb.Table(columns=[\"class\", \"precision\", \"recall\", \"f1-score\", \"support\"])\n",
    "    \n",
    "    # Populate the table\n",
    "    for class_name, metrics in class_report.items():\n",
    "        if class_name not in ['accuracy', 'macro avg', 'weighted avg']:  # Skip overall avg metrics\n",
    "            class_report_table.add_data(\n",
    "                class_name, \n",
    "                metrics[\"precision\"], \n",
    "                metrics[\"recall\"], \n",
    "                metrics[\"f1-score\"], \n",
    "                metrics[\"support\"]\n",
    "            )\n",
    "    \n",
    "    # Log the table to WandB\n",
    "    wandb.log({\"Classification Report\": class_report_table})\n",
    "    \n",
    "    # You can also log the metrics separately if needed (for overall comparison/graphing)\n",
    "    wandb.log({\n",
    "        \"precision_avg\": class_report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall_avg\": class_report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1-score_avg\": class_report[\"weighted avg\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    # Convert confusion matrix into a DataFrame for better clarity\n",
    "    conf_df = pd.DataFrame(conf_matrix)\n",
    "    wandb.log({\"Confusion Matrix\": wandb.Table(dataframe=conf_df)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
