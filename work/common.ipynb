{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b16da7f-91fb-495d-bade-a254058e90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, predictions, heading='-----Evaluation-----'):\n",
    "    print(heading)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    categories = np.unique(y_test)\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in categories], columns = [i for i in categories])\n",
    "    sns.heatmap(df_cm,annot=True,cmap='Reds')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "def remove_files_from_directory(directory):\n",
    "    # Get all files in the directory\n",
    "    files = glob.glob(os.path.join(directory, \"*\"))\n",
    "    \n",
    "    # Loop through the files and remove each one\n",
    "    for file in files:\n",
    "        if os.path.isfile(file):\n",
    "            os.remove(file)\n",
    "    \n",
    "    print(f\"All files in {directory} have been removed.\")\n",
    "\n",
    "def get_anomaly_X_y_from_csv(csv_file, main_labels, target_column, normal_target, output_folder):\n",
    "    df=pd.read_csv(os.path.join(output_folder, csv_file),usecols=main_labels)\n",
    "    df=df.fillna(0)\n",
    "    anomaly_or_not=[]\n",
    "    for i in df[target_column]: #it changes the normal label to \"1\" and the anomaly tag to \"0\" for use in the machine learning algorithm\n",
    "        if i == normal_target:\n",
    "            anomaly_or_not.append(1)\n",
    "        else:\n",
    "            anomaly_or_not.append(0)           \n",
    "    df[target_column]=anomaly_or_not\n",
    "\n",
    "    # y = df[target_column].values\n",
    "    # del df[target_column]\n",
    "    # X = df.values\n",
    "    y_df = df[target_column]\n",
    "    X_df = df.drop(columns=[target_column])\n",
    "    \n",
    "    # X = np.float32(X)\n",
    "    # X[np.isnan(X)] = 0\n",
    "    # X[np.isinf(X)] = 0\n",
    "    # print('X', type(X), X)\n",
    "    # print('y', type(y), y)\n",
    "    return (X_df, y_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f8bdc91-972e-4af9-b9f0-fd1705e60a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, categorical_columns):\n",
    "    # Initialize the OneHotEncoder\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    \n",
    "    # Create a copy of the DataFrame for encoding\n",
    "    X_encoded = df.copy()\n",
    "    \n",
    "    # List to store the one-hot encoded DataFrames\n",
    "    encoded_dfs = []\n",
    "    \n",
    "    # Loop over categorical columns to encode them\n",
    "    for col in categorical_columns:\n",
    "        # Fit and transform the column with one-hot encoding\n",
    "        encoded_array = ohe.fit_transform(X_encoded[[col]])\n",
    "        \n",
    "        # Create a DataFrame for the one-hot encoded columns\n",
    "        encoded_columns = ohe.get_feature_names_out([col])\n",
    "        encoded_df = pd.DataFrame(encoded_array, columns=encoded_columns, index=X_encoded.index)\n",
    "        \n",
    "        # Append the encoded DataFrame to the list\n",
    "        encoded_dfs.append(encoded_df)\n",
    "    \n",
    "    # Drop the original categorical columns from the DataFrame\n",
    "    X_encoded = X_encoded.drop(columns=categorical_columns)\n",
    "    \n",
    "    # Concatenate the original DataFrame (without categorical columns) with the encoded DataFrames\n",
    "    X_encoded = pd.concat([X_encoded] + encoded_dfs, axis=1)\n",
    "    \n",
    "    # Ensure the DataFrame is de-fragmented by making a copy\n",
    "    X_encoded = X_encoded.copy()\n",
    "    \n",
    "    # print(list(X_encoded.columns))\n",
    "    return (ohe, X_encoded)\n",
    "\n",
    "def label_encode(df, columns):\n",
    "    le = LabelEncoder()\n",
    "    X_encoded = df.copy()\n",
    "    for col in columns:\n",
    "        X_encoded[col] = le.fit_transform(X_encoded[col])\n",
    "    return (le, X_encoded)\n",
    "\n",
    "def standardise(df, columns, scaler=None):\n",
    "    X_standardised = df.copy()\n",
    "    \n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        # Fit and transform the numeric columns\n",
    "        X_standardised[columns] = scaler.fit_transform(X_standardised[columns])\n",
    "    else:\n",
    "        X_standardised[columns] = scaler.transform(X_standardised[columns])\n",
    "    return (scaler, X_standardised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b2db07-4c69-4ac5-8465-061761bf7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing_values(all_df):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    sns.heatmap(all_df.isnull(),cbar=False,cmap='Wistia',yticklabels=False)\n",
    "    plt.title('Missing value in the dataset');\n",
    "\n",
    "def show_target_values(all_df, target_column):\n",
    "    target_counts = all_df[target_column].value_counts()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,7))\n",
    "    target_counts_barplot = sns.barplot(x = target_counts.index,y = target_counts.values, ax = ax[0], hue=target_counts.index, palette='Set2', legend=False)\n",
    "    target_counts_barplot.set_ylabel('Number of classes in the dataset')\n",
    "    \n",
    "    target_counts.plot.pie(autopct=\"%1.1f%%\", ax=ax[1])\n",
    "\n",
    "def show_feature_correlation(all_df):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.heatmap(all_df.corr(), cmap='hsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ec0dd-845a-40cd-ac58-e6cb4be0e03c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
