{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd8ef74-fabc-49fd-a05b-2673a6d224bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import fetch_covtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6efa38a8-1a2c-4734-9441-06e8d68f0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'common.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc12412-c7f3-4a4b-adb6-2f98a2d05885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate and print model performance\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Print model evaluation metrics\n",
    "    evaluate(y_test, y_pred, f\"\\nModel: {model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c743da3c-33ea-43fa-9c4c-0dfd4d58e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMAL_TARGET = 2\n",
    "TARGET_COLUMN = 'Cover_Type'\n",
    "\n",
    "NUMERICAL_COLUMNS = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', \n",
    "                     'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', \n",
    "                     'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', \n",
    "                     'Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "# Dictionary to store models and their names\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Support Vector Machine (SVM)\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edf7a9cf-d515-4d73-8e61-8b52263499ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type_31</th>\n",
       "      <th>Soil_Type_32</th>\n",
       "      <th>Soil_Type_33</th>\n",
       "      <th>Soil_Type_34</th>\n",
       "      <th>Soil_Type_35</th>\n",
       "      <th>Soil_Type_36</th>\n",
       "      <th>Soil_Type_37</th>\n",
       "      <th>Soil_Type_38</th>\n",
       "      <th>Soil_Type_39</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0     2596.0    51.0    3.0                             258.0   \n",
       "1     2590.0    56.0    2.0                             212.0   \n",
       "2     2804.0   139.0    9.0                             268.0   \n",
       "3     2785.0   155.0   18.0                             242.0   \n",
       "4     2595.0    45.0    2.0                             153.0   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                             0.0                            510.0   \n",
       "1                            -6.0                            390.0   \n",
       "2                            65.0                           3180.0   \n",
       "3                           118.0                           3090.0   \n",
       "4                            -1.0                            391.0   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0          221.0           232.0          148.0   \n",
       "1          220.0           235.0          151.0   \n",
       "2          234.0           238.0          135.0   \n",
       "3          238.0           238.0          122.0   \n",
       "4          220.0           234.0          150.0   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type_31  Soil_Type_32  \\\n",
       "0                              6279.0  ...           0.0           0.0   \n",
       "1                              6225.0  ...           0.0           0.0   \n",
       "2                              6121.0  ...           0.0           0.0   \n",
       "3                              6211.0  ...           0.0           0.0   \n",
       "4                              6172.0  ...           0.0           0.0   \n",
       "\n",
       "   Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  Soil_Type_37  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   Soil_Type_38  Soil_Type_39  Cover_Type  \n",
       "0           0.0           0.0           5  \n",
       "1           0.0           0.0           5  \n",
       "2           0.0           0.0           2  \n",
       "3           0.0           0.0           2  \n",
       "4           0.0           0.0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Cover Type dataset\n",
    "data = fetch_covtype(as_frame=True)\n",
    "X_data = data['data']\n",
    "y_data = data['target']\n",
    "\n",
    "all_df = pd.concat([X_data, y_data], axis=1)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d121a1c5-c0d7-4bf9-89f5-1fb750869eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(464809, 54) (116203, 54) (464809,) (116203,)\n"
     ]
    }
   ],
   "source": [
    "# Get X and y from all_df\n",
    "X_df = all_df.drop(columns=[TARGET_COLUMN])\n",
    "y_df = all_df[TARGET_COLUMN]\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n",
    "print(X_train_df.shape, X_test_df.shape, y_train_df.shape, y_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c10230c-c0d7-46e7-bbbe-df0a40106c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features (required for some models, especially SVM)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# columns_to_scale = all_df.columns.get_indexer(NUMERICAL_COLUMNS)\n",
    "# print('columns_to_scale', columns_to_scale)\n",
    "\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled_df = X_train_df.copy()\n",
    "X_train_scaled_df[NUMERICAL_COLUMNS] = scaler.fit_transform(X_train_scaled_df[NUMERICAL_COLUMNS])\n",
    "\n",
    "X_test_scaled_df = X_test_df.copy()\n",
    "X_test_scaled_df[NUMERICAL_COLUMNS] = scaler.transform(X_test_scaled_df[NUMERICAL_COLUMNS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e05c2-ec47-4f67-8716-9197a9e687f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: LogisticRegression\n",
      "Confusion Matrix:\n",
      "[[29810 11841     8     0     0    18   880]\n",
      " [10257 45243   618     2    46   306    28]\n",
      " [    0   741  5693   129     4   554     0]\n",
      " [    0     1   259   210     0    56     0]\n",
      " [   12  1889    69     0    15    10     0]\n",
      " [    0   820  1718    28     3   920     0]\n",
      " [ 1669    39     0     0     0     0  2307]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.71     42557\n",
      "           2       0.75      0.80      0.77     56500\n",
      "           3       0.68      0.80      0.74      7121\n",
      "           4       0.57      0.40      0.47       526\n",
      "           5       0.22      0.01      0.01      1995\n",
      "           6       0.49      0.26      0.34      3489\n",
      "           7       0.72      0.57      0.64      4015\n",
      "\n",
      "    accuracy                           0.72    116203\n",
      "   macro avg       0.59      0.51      0.53    116203\n",
      "weighted avg       0.71      0.72      0.71    116203\n",
      "\n",
      "Accuracy: 0.7245768181544366\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "Confusion Matrix:\n",
      "[[39919  2394     1     0    44     4   195]\n",
      " [ 2356 53593   169     1   245   103    33]\n",
      " [    3   138  6634    52    19   273     2]\n",
      " [    0     1    71   431     0    23     0]\n",
      " [   45   260    28     0  1651    11     0]\n",
      " [    5   102   255    24    11  3092     0]\n",
      " [  168    23     0     0     1     0  3823]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.94      0.94     42557\n",
      "           2       0.95      0.95      0.95     56500\n",
      "           3       0.93      0.93      0.93      7121\n",
      "           4       0.85      0.82      0.83       526\n",
      "           5       0.84      0.83      0.83      1995\n",
      "           6       0.88      0.89      0.88      3489\n",
      "           7       0.94      0.95      0.95      4015\n",
      "\n",
      "    accuracy                           0.94    116203\n",
      "   macro avg       0.90      0.90      0.90    116203\n",
      "weighted avg       0.94      0.94      0.94    116203\n",
      "\n",
      "Accuracy: 0.9392442535906991\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "Confusion Matrix:\n",
      "[[40129  2327     1     0     8     3    89]\n",
      " [ 1219 55029    93     0    80    63    16]\n",
      " [    2    92  6874    25     6   122     0]\n",
      " [    0     0    65   446     0    15     0]\n",
      " [   34   396    18     0  1536    11     0]\n",
      " [    1   105   228    18     3  3134     0]\n",
      " [  174    27     0     0     0     0  3814]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.94      0.95     42557\n",
      "           2       0.95      0.97      0.96     56500\n",
      "           3       0.94      0.97      0.95      7121\n",
      "           4       0.91      0.85      0.88       526\n",
      "           5       0.94      0.77      0.85      1995\n",
      "           6       0.94      0.90      0.92      3489\n",
      "           7       0.97      0.95      0.96      4015\n",
      "\n",
      "    accuracy                           0.95    116203\n",
      "   macro avg       0.95      0.91      0.92    116203\n",
      "weighted avg       0.96      0.95      0.95    116203\n",
      "\n",
      "Accuracy: 0.9548978942023872\n",
      "\n",
      "Model: GradientBoostingClassifier\n",
      "Confusion Matrix:\n",
      "[[31925 10137    17     0    26    17   435]\n",
      " [ 8815 46679   507     0   131   344    24]\n",
      " [    0   672  5882    86     6   475     0]\n",
      " [    0     0   129   382     0    15     0]\n",
      " [   20  1442    44     0   485     4     0]\n",
      " [    0   744  1041    28     0  1676     0]\n",
      " [ 1200    34     0     0     0     0  2781]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.75      0.76     42557\n",
      "           2       0.78      0.83      0.80     56500\n",
      "           3       0.77      0.83      0.80      7121\n",
      "           4       0.77      0.73      0.75       526\n",
      "           5       0.75      0.24      0.37      1995\n",
      "           6       0.66      0.48      0.56      3489\n",
      "           7       0.86      0.69      0.77      4015\n",
      "\n",
      "    accuracy                           0.77    116203\n",
      "   macro avg       0.76      0.65      0.68    116203\n",
      "weighted avg       0.77      0.77      0.77    116203\n",
      "\n",
      "Accuracy: 0.7728716126089687\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "Confusion Matrix:\n",
      "[[41202  1252     1     0    28     3    71]\n",
      " [ 1138 55110    71     0   119    47    15]\n",
      " [    3    84  6911    18     7    98     0]\n",
      " [    0     1    74   416     0    35     0]\n",
      " [   25   154    17     0  1789    10     0]\n",
      " [    4    83   124    16     8  3254     0]\n",
      " [  108    24     0     0     0     0  3883]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.97      0.97     42557\n",
      "           2       0.97      0.98      0.97     56500\n",
      "           3       0.96      0.97      0.97      7121\n",
      "           4       0.92      0.79      0.85       526\n",
      "           5       0.92      0.90      0.91      1995\n",
      "           6       0.94      0.93      0.94      3489\n",
      "           7       0.98      0.97      0.97      4015\n",
      "\n",
      "    accuracy                           0.97    116203\n",
      "   macro avg       0.95      0.93      0.94    116203\n",
      "weighted avg       0.97      0.97      0.97    116203\n",
      "\n",
      "Accuracy: 0.9686927187766237\n"
     ]
    }
   ],
   "source": [
    "# Loop through models and evaluate each one\n",
    "for model_name, model in models.items():\n",
    "    # For SVM and Logistic Regression, use scaled data\n",
    "    if model_name in [\"Logistic Regression\", \"Support Vector Machine (SVM)\"]:\n",
    "        evaluate_model(model, X_train_scaled_df, y_train_df, X_test_scaled_df, y_test_df)\n",
    "    else:\n",
    "        evaluate_model(model, X_train_df, y_train_df, X_test_df, y_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6531bb3-53d7-42e9-bf54-6e8dcacb0b2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m cols\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# attacks = open(\"./datasets/kdd/training_attack_types\",'r').read()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# attacks = {t[0] : t[1] for t in (t.split(' ') for t in attacks.split('\\n')) if len(t) == 2}\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# attacks['normal'] = 'normal'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# attacks\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m all_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./datasets/kdd/corrected\u001b[39m\u001b[38;5;124m\"\u001b[39m, names \u001b[38;5;241m=\u001b[39m cols)\n\u001b[1;32m     11\u001b[0m all_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattack\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattack\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m r:TARGET_DICT[r[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal class: \u001b[39m\u001b[38;5;124m'\u001b[39m, all_df[TARGET_COLUMN]\u001b[38;5;241m.\u001b[39mmode())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "cols = open(\"./datasets/kdd/kddcup.names\",'r').read()\n",
    "cols = [c[:c.index(':')] for c in cols.split('\\n')[1:-1]]\n",
    "cols.append('attack')\n",
    "\n",
    "# attacks = open(\"./datasets/kdd/training_attack_types\",'r').read()\n",
    "# attacks = {t[0] : t[1] for t in (t.split(' ') for t in attacks.split('\\n')) if len(t) == 2}\n",
    "# attacks['normal'] = 'normal'\n",
    "# attacks\n",
    "\n",
    "all_df = pd.read_csv(\"./datasets/kdd/corrected\", names = cols)\n",
    "all_df['attack'] = all_df['attack'].apply(lambda r:TARGET_DICT[r[:-1]])\n",
    "\n",
    "print('Normal class: ', all_df[TARGET_COLUMN].mode())\n",
    "print('Feature  names: ', data.feature_names)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23242d24-504a-455a-abd4-2f16bc16f4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
